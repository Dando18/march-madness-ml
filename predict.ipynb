{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting March Madness Brackets\n",
    "\n",
    "Can we use historical results to predict march madness results? \n",
    "\n",
    "Use 2 datasets\n",
    "cbb.csv - End of seasons stats for each team from 2013 to 2021 (https://www.kaggle.com/andrewsundberg/college-basketball-dataset)\n",
    "big_dance.csv - Tournament results from 1985 to 2019 (https://data.world/michaelaroy/ncaa-tournament-results/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std imports\n",
    "from os.path import join as path_join\n",
    "from os import makedirs\n",
    "import math\n",
    "\n",
    "# tpl imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import SGDClassifier, Perceptron, LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters\n",
    "MIN_YEAR = 2008\n",
    "MAX_YEAR = 2021\n",
    "EXCLUDE_YEARS = [2020]  # just 2020 for now cause of covid\n",
    "DUPLICATE_GAMES = True  # swap order of teams in row and duplicate game in dataset\n",
    "ENCODE_CONF = True  # use Conference as training feature\n",
    "NORMALIZE = True # normalize features\n",
    "NUM_FEATURES = None # set to None to do no dimensionality reduction\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data sets\n",
    "\n",
    "# keyed on TEAM, CONF, YEAR\n",
    "season_stats_df = pd.read_csv(path_join('data', 'raw_cbb.csv'), index_col=0)\n",
    "\n",
    "# keyed on year, round, region_number, seed, seed_2 (or year, round, team, team_2)\n",
    "tournament_stats_df = pd.read_csv(path_join('data', 'tournament-results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1512 entries, 0 to 1511\n",
      "Data columns (total 57 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Year            1512 non-null   int64  \n",
      " 1   Round           1512 non-null   int64  \n",
      " 2   Region Number   1512 non-null   int64  \n",
      " 3   Region Name     1512 non-null   object \n",
      " 4   Seed_1          1512 non-null   int64  \n",
      " 5   Score_1         1512 non-null   int64  \n",
      " 6   Team_1          1512 non-null   object \n",
      " 7   Team_2          1512 non-null   object \n",
      " 8   Score_2         1512 non-null   int64  \n",
      " 9   Seed_2          1512 non-null   int64  \n",
      " 10  winner          1512 non-null   int64  \n",
      " 11  ADJOE_team_1    1512 non-null   float64\n",
      " 12  ADJDE_team_1    1512 non-null   float64\n",
      " 13  BARTHAG_team_1  1512 non-null   float64\n",
      " 14  RECORD_team_1   1512 non-null   object \n",
      " 15  W_team_1        1512 non-null   int64  \n",
      " 16  G_team_1        1512 non-null   int64  \n",
      " 17  EFG_O_team_1    1512 non-null   float64\n",
      " 18  EFG_D_team_1    1512 non-null   float64\n",
      " 19  FTR_team_1      1512 non-null   float64\n",
      " 20  FTRD_team_1     1512 non-null   float64\n",
      " 21  TOR_team_1      1512 non-null   float64\n",
      " 22  TORD_team_1     1512 non-null   float64\n",
      " 23  ORB_team_1      1512 non-null   float64\n",
      " 24  DRB_team_1      1512 non-null   float64\n",
      " 25  2P_O_team_1     1512 non-null   float64\n",
      " 26  2P_D_team_1     1512 non-null   float64\n",
      " 27  3P_O_team_1     1512 non-null   float64\n",
      " 28  3P_D_team_1     1512 non-null   float64\n",
      " 29  ADJ_T_team_1    1512 non-null   float64\n",
      " 30  WAB_team_1      1512 non-null   float64\n",
      " 31  CONF_team_1     1512 non-null   object \n",
      " 32  WR_team_1       1512 non-null   float64\n",
      " 33  CONF_ID_team_1  1512 non-null   int64  \n",
      " 34  ADJOE_team_2    1512 non-null   float64\n",
      " 35  ADJDE_team_2    1512 non-null   float64\n",
      " 36  BARTHAG_team_2  1512 non-null   float64\n",
      " 37  RECORD_team_2   1512 non-null   object \n",
      " 38  W_team_2        1512 non-null   int64  \n",
      " 39  G_team_2        1512 non-null   int64  \n",
      " 40  EFG_O_team_2    1512 non-null   float64\n",
      " 41  EFG_D_team_2    1512 non-null   float64\n",
      " 42  FTR_team_2      1512 non-null   float64\n",
      " 43  FTRD_team_2     1512 non-null   float64\n",
      " 44  TOR_team_2      1512 non-null   float64\n",
      " 45  TORD_team_2     1512 non-null   float64\n",
      " 46  ORB_team_2      1512 non-null   float64\n",
      " 47  DRB_team_2      1512 non-null   float64\n",
      " 48  2P_O_team_2     1512 non-null   float64\n",
      " 49  2P_D_team_2     1512 non-null   float64\n",
      " 50  3P_O_team_2     1512 non-null   float64\n",
      " 51  3P_D_team_2     1512 non-null   float64\n",
      " 52  ADJ_T_team_2    1512 non-null   float64\n",
      " 53  WAB_team_2      1512 non-null   float64\n",
      " 54  CONF_team_2     1512 non-null   object \n",
      " 55  WR_team_2       1512 non-null   float64\n",
      " 56  CONF_ID_team_2  1512 non-null   int64  \n",
      "dtypes: float64(36), int64(14), object(7)\n",
      "memory usage: 685.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# preprocess datasets\n",
    "\n",
    "# select valid years in each\n",
    "season_stats_df.drop(season_stats_df[\n",
    "    (season_stats_df['YEAR'] < MIN_YEAR) | (season_stats_df['YEAR'] > MAX_YEAR) | (season_stats_df['YEAR'].isin(EXCLUDE_YEARS))\n",
    "    ].index, inplace=True)\n",
    "tournament_stats_df.drop(tournament_stats_df[\n",
    "    (tournament_stats_df['Year'] < MIN_YEAR) | (tournament_stats_df['Year'] > MAX_YEAR) | (tournament_stats_df['Year'].isin(EXCLUDE_YEARS))\n",
    "    ].index, inplace=True)\n",
    "\n",
    "# handle difference in team naming (remove period from 'St.' in stat dataset; other fixed rules)\n",
    "season_stats_df['TEAM'] = season_stats_df['TEAM'].str.replace('St.', 'St', regex=False)\n",
    "substitutions = {'Saint Louis': 'St Louis', 'Saint Joseph\\'s': 'St Josephs', 'St John\\'s': 'St Johns', \n",
    "                'North Carolina St': 'NC State', 'Saint Mary\\'s': 'St Marys', 'Mississippi': 'Ole Miss',\n",
    "                'Stephen F. Austin': 'Stephen F Austin', 'Middle Tennessee': 'Middle Tennessee St',\n",
    "                'Miami OH': 'Miami Ohio', 'Miami FL': 'Miami', 'Penn': 'Pennsylvania', \n",
    "                'Mount St Mary\\'s': 'Mount St Marys', 'Cal Irvine': 'UC Irvine', 'UCF': 'Central Florida',\n",
    "                'Green Bay': 'Wisconsin Green Bay', 'Milwaukee': 'Wisconsin Milwaukee', 'UTSA': 'Texas San Antonio',\n",
    "                'UC Santa Barbara': 'Santa Barbara', 'Southern Miss': 'Southern Mississippi',\n",
    "                'UT Arlington': 'Texas Arlington', 'Saint Peter\\'s': 'St Peters', \n",
    "                'LIU Brooklyn': 'Long Island Brooklyn', 'Loyola MD': 'Loyola Maryland'}\n",
    "season_stats_df.replace(to_replace=substitutions, value=None, inplace=True)\n",
    "\n",
    "stat_teams = set(season_stats_df['TEAM'].values)\n",
    "tournament_teams = set(tournament_stats_df['Team_1'].values)\n",
    "tournament_teams.update(tournament_stats_df['Team_2'].values)\n",
    "assert len(tournament_teams.difference(stat_teams)) == 0, \"Teams in Tournament, but not in Stats: {}\".format(tournament_teams.difference(stat_teams))\n",
    "\n",
    "# duplicate games\n",
    "if DUPLICATE_GAMES:\n",
    "    cols2dup = ['Seed_1', 'Score_1', 'Team_1'], ['Seed_2', 'Score_2', 'Team_2']\n",
    "    swap = tournament_stats_df.rename(columns={**dict(zip(cols2dup[0], cols2dup[1])), **dict(zip(cols2dup[1], cols2dup[0]))})\n",
    "    tournament_stats_df = tournament_stats_df.append(swap).sort_index(ignore_index=True)\n",
    "\n",
    "# add win column (1 if team_1 won; 0 if team_2 won)\n",
    "tournament_stats_df['winner'] = 0\n",
    "tournament_stats_df.loc[tournament_stats_df['Score_1'] > tournament_stats_df['Score_2'], 'winner'] = 1\n",
    "\n",
    "# add win_rate column\n",
    "season_stats_df['WR'] = season_stats_df['W'] / season_stats_df['G']\n",
    "\n",
    "# add conference embedding\n",
    "if ENCODE_CONF:\n",
    "    season_stats_df['CONF_ID'] = season_stats_df.groupby('CONF').ngroup().add(1)\n",
    "\n",
    "# join team_1 with season_stats\n",
    "data = tournament_stats_df.merge(season_stats_df, how='left', left_on=['Year', 'Team_1'], right_on=['YEAR', 'TEAM'], validate='m:1')\n",
    "data.drop(columns=['TEAM', 'YEAR'], inplace=True)\n",
    "\n",
    "# join team_2 with season_stats\n",
    "data = data.merge(season_stats_df, how='left', left_on=['Year', 'Team_2'], right_on=['YEAR', 'TEAM'], suffixes=('_team_1', '_team_2'), validate='m:1')\n",
    "data.drop(columns=['TEAM', 'YEAR'], inplace=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "We want to predict the the column _winner_ using  the rest of the stat columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_best(Classifier, X, y, tune=None, **params):\n",
    "    ''' Find an approximate best score from clf on X and y.\n",
    "    '''\n",
    "    print('Training classifier \\'{}\\'...'.format(Classifier.__name__))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=SEED, shuffle=True)\n",
    "    clf = Classifier(**params)\n",
    "    best_score = 0\n",
    "\n",
    "    if tune:\n",
    "        search = GridSearchCV(clf, tune, refit=True)\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "        best_params = search.best_params_\n",
    "        best_score = search.best_score_\n",
    "        print('{} scores: {}\\twith {}'.format(Classifier.__name__, best_score, best_params))\n",
    "        clf = search.best_estimator_\n",
    "    else:\n",
    "        cv_results = cross_validate(clf, X, y, cv=5)\n",
    "        scores = cv_results['test_score']\n",
    "        best_score = np.mean(scores)\n",
    "        print('{} scores: {} ± {}'.format(Classifier.__name__, best_score, np.std(scores)))\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    #y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    #print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    if hasattr(clf, 'feature_importances_') and hasattr(clf, 'feature_names_in_'):\n",
    "        importances = sorted(zip(clf.feature_names_in_, clf.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "        print('Feature Importances: {}'.format(importances))\n",
    "    \n",
    "    return clf, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data set\n",
    "stat_features = ['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D', 'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD',\n",
    "                '2P_O', '2P_D', '3P_O', '3P_D', 'ADJ_T']\n",
    "if ENCODE_CONF:\n",
    "    stat_features.append('CONF_ID')\n",
    "stat_features = [x + suffix for suffix in ('_team_1', '_team_2') for x in stat_features]\n",
    "features = ['Round', 'Seed_1', 'Seed_2', *stat_features]\n",
    "\n",
    "# normalize columns\n",
    "normalized_features = ['Seed_1', 'Seed_2', *stat_features]\n",
    "#normalized_features = [x + suffix for suffix in ('_team_1', '_team_2') for x in normalized_features]\n",
    "scaler = StandardScaler()\n",
    "if NORMALIZE:\n",
    "    scaler.fit(data[normalized_features])\n",
    "    data[normalized_features] = scaler.transform(data[normalized_features])\n",
    "\n",
    "X, y = data[features], data['winner']\n",
    "\n",
    "# dimensionality reduction\n",
    "dimensions_reduced = False\n",
    "if NUM_FEATURES and NUM_FEATURES < len(features):\n",
    "    assert NUM_FEATURES > 0, 'Must have positive number of features'\n",
    "    dimensions_reduced = True\n",
    "    \n",
    "    pca = PCA(n_components=NUM_FEATURES)\n",
    "    X = pca.fit_transform(X)\n",
    "    print('Reduced to {} features.'.format(pca.n_components_))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier 'DummyClassifier'...\n",
      "DummyClassifier scores: 0.5152252311323847 ± 0.01613695687415327\n",
      "Training classifier 'LinearRegression'...\n",
      "LinearRegression scores: 0.2471556717003315\twith {'fit_intercept': True, 'positive': False}\n",
      "\n",
      "Training classifier 'GradientBoostingClassifier'...\n",
      "GradientBoostingClassifier scores: 0.7035019455252918\twith {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "Feature Importances: [('BARTHAG_team_2', 0.40550788497028156), ('BARTHAG_team_1', 0.38163695823873656), ('Seed_1', 0.12405866806084556), ('ADJOE_team_1', 0.03181207504836634), ('Seed_2', 0.01742546405913501), ('ADJDE_team_1', 0.010422295842411491), ('ADJOE_team_2', 0.00594923790346173), ('FTR_team_1', 0.0057783300427472345), ('ORB_team_1', 0.0051984457215768195), ('3P_O_team_2', 0.003732162570784178), ('FTR_team_2', 0.003677789770169024), ('3P_D_team_2', 0.002248989126021735), ('2P_D_team_1', 0.001189816723078558), ('DRB_team_2', 0.0007145172292130287), ('3P_D_team_1', 0.0006473646931713029), ('Round', 0.0), ('G_team_1', 0.0), ('W_team_1', 0.0), ('EFG_O_team_1', 0.0), ('EFG_D_team_1', 0.0), ('TOR_team_1', 0.0), ('TORD_team_1', 0.0), ('DRB_team_1', 0.0), ('FTRD_team_1', 0.0), ('2P_O_team_1', 0.0), ('3P_O_team_1', 0.0), ('ADJ_T_team_1', 0.0), ('CONF_ID_team_1', 0.0), ('G_team_2', 0.0), ('W_team_2', 0.0), ('ADJDE_team_2', 0.0), ('EFG_O_team_2', 0.0), ('EFG_D_team_2', 0.0), ('TOR_team_2', 0.0), ('TORD_team_2', 0.0), ('ORB_team_2', 0.0), ('FTRD_team_2', 0.0), ('2P_O_team_2', 0.0), ('2P_D_team_2', 0.0), ('ADJ_T_team_2', 0.0), ('CONF_ID_team_2', 0.0)]\n",
      "\n",
      "Training classifier 'SVC'...\n",
      "SVC scores: 0.7198443579766537\twith {'C': 10.0, 'kernel': 'linear'}\n",
      "\n",
      "Training classifier 'SGDClassifier'...\n",
      "SGDClassifier scores: 0.6926070038910506\twith {'alpha': 0.001, 'learning_rate': 'optimal', 'loss': 'modified_huber', 'max_iter': 100000.0}\n",
      "\n",
      "Training classifier 'GaussianNB'...\n",
      "GaussianNB scores: 0.7123073896793652 ± 0.025895354960687227\n",
      "\n",
      "Training classifier 'Perceptron'...\n",
      "Perceptron scores: 0.6547155377789435 ± 0.05814995234307953\n",
      "\n",
      "Training classifier 'MLPClassifier'...\n",
      "MLPClassifier scores: 0.6770428015564203\twith {'batch_size': 16, 'hidden_layer_sizes': (128, 128, 64), 'max_iter': 10000, 'solver': 'adam'}\n",
      "\n",
      "Training classifier 'AdaBoostClassifier'...\n",
      "AdaBoostClassifier scores: 0.709727626459144\twith {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Feature Importances: [('BARTHAG_team_1', 0.36), ('BARTHAG_team_2', 0.34), ('Seed_2', 0.08), ('Seed_1', 0.06), ('ADJDE_team_2', 0.06), ('ADJDE_team_1', 0.04), ('W_team_1', 0.02), ('ADJOE_team_1', 0.02), ('W_team_2', 0.02), ('Round', 0.0), ('G_team_1', 0.0), ('EFG_O_team_1', 0.0), ('EFG_D_team_1', 0.0), ('TOR_team_1', 0.0), ('TORD_team_1', 0.0), ('ORB_team_1', 0.0), ('DRB_team_1', 0.0), ('FTR_team_1', 0.0), ('FTRD_team_1', 0.0), ('2P_O_team_1', 0.0), ('2P_D_team_1', 0.0), ('3P_O_team_1', 0.0), ('3P_D_team_1', 0.0), ('ADJ_T_team_1', 0.0), ('CONF_ID_team_1', 0.0), ('G_team_2', 0.0), ('ADJOE_team_2', 0.0), ('EFG_O_team_2', 0.0), ('EFG_D_team_2', 0.0), ('TOR_team_2', 0.0), ('TORD_team_2', 0.0), ('ORB_team_2', 0.0), ('DRB_team_2', 0.0), ('FTR_team_2', 0.0), ('FTRD_team_2', 0.0), ('2P_O_team_2', 0.0), ('2P_D_team_2', 0.0), ('3P_O_team_2', 0.0), ('3P_D_team_2', 0.0), ('ADJ_T_team_2', 0.0), ('CONF_ID_team_2', 0.0)]\n",
      "\n",
      "Training classifier 'KNeighborsClassifier'...\n",
      "KNeighborsClassifier scores: 0.6832684824902724\twith {'n_neighbors': 25, 'p': 3, 'weights': 'uniform'}\n",
      "\n",
      "Training classifier 'DecisionTreeClassifier'...\n",
      "DecisionTreeClassifier scores: 0.6357976653696498\twith {'criterion': 'gini', 'splitter': 'best'}\n",
      "Feature Importances: [('BARTHAG_team_1', 0.17086184359696446), ('BARTHAG_team_2', 0.15353128662288432), ('ADJOE_team_2', 0.042750117655298764), ('TORD_team_2', 0.04013917946127369), ('ADJOE_team_1', 0.03530110403120348), ('G_team_2', 0.03246317529034492), ('ADJ_T_team_2', 0.03076887552649486), ('FTR_team_1', 0.026690685532544604), ('ADJDE_team_1', 0.02476881732904876), ('FTRD_team_2', 0.02404439008980695), ('FTRD_team_1', 0.022997527374841505), ('ADJDE_team_2', 0.022498931533433963), ('3P_O_team_2', 0.021022623458198293), ('DRB_team_2', 0.0199773091494977), ('3P_D_team_1', 0.018782985395409884), ('CONF_ID_team_1', 0.018458021619911363), ('ORB_team_2', 0.018427364680824686), ('ADJ_T_team_1', 0.017789095877532093), ('W_team_2', 0.017772108262072407), ('FTR_team_2', 0.01725396459030417), ('TORD_team_1', 0.0163431277755313), ('W_team_1', 0.016180334681942538), ('DRB_team_1', 0.015240934323142427), ('Seed_1', 0.014351682820567918), ('2P_D_team_2', 0.014258474667416227), ('TOR_team_2', 0.013132059149765313), ('2P_O_team_2', 0.012813721859791412), ('CONF_ID_team_2', 0.01111503129994703), ('3P_O_team_1', 0.011032850632747442), ('ORB_team_1', 0.011021672287951135), ('EFG_D_team_2', 0.010950387447266162), ('Seed_2', 0.01093307682830923), ('EFG_O_team_1', 0.010143550066096407), ('3P_D_team_2', 0.01010857471561243), ('2P_D_team_1', 0.009523171610322442), ('G_team_1', 0.009009943164128304), ('TOR_team_1', 0.006912341105393188), ('EFG_D_team_1', 0.006840061484214454), ('EFG_O_team_2', 0.006567288832444865), ('2P_O_team_1', 0.005665886993470087), ('Round', 0.0015564211760487976)]\n",
      "\n",
      "Training classifier 'RandomForestClassifier'...\n",
      "RandomForestClassifier scores: 0.6996108949416342\twith {'criterion': 'entropy', 'n_estimators': 200}\n",
      "Feature Importances: [('BARTHAG_team_2', 0.06539932181476962), ('BARTHAG_team_1', 0.06479237044256923), ('Seed_2', 0.04049705436922012), ('ADJOE_team_1', 0.038953582654890476), ('Seed_1', 0.03868471999219346), ('ADJDE_team_2', 0.038475017323068746), ('ADJDE_team_1', 0.03653127113937637), ('ADJOE_team_2', 0.034620017490062195), ('ORB_team_2', 0.024787986980797108), ('TORD_team_2', 0.023199325457506248), ('FTR_team_2', 0.022853329054042137), ('FTRD_team_1', 0.022128231090795106), ('ORB_team_1', 0.022053429717877573), ('W_team_2', 0.02190576935690406), ('3P_D_team_2', 0.02186031552219564), ('ADJ_T_team_1', 0.021743041318811968), ('ADJ_T_team_2', 0.021690009998656026), ('3P_D_team_1', 0.021661009944557507), ('FTRD_team_2', 0.021445376362610513), ('FTR_team_1', 0.0214352449078406), ('EFG_D_team_1', 0.021432465442222874), ('DRB_team_1', 0.021306628949455727), ('W_team_1', 0.021043562305158872), ('TORD_team_1', 0.020522755436226718), ('EFG_D_team_2', 0.02045691100553176), ('TOR_team_2', 0.020442075542807733), ('2P_D_team_2', 0.020104693868751296), ('DRB_team_2', 0.01998931351853056), ('3P_O_team_2', 0.01955264039607418), ('TOR_team_1', 0.019297416693337628), ('EFG_O_team_1', 0.019267086210634627), ('EFG_O_team_2', 0.019252937086164316), ('2P_O_team_1', 0.019157222882502534), ('2P_O_team_2', 0.01906333266413436), ('2P_D_team_1', 0.018677949267890896), ('3P_O_team_1', 0.018592477811847363), ('CONF_ID_team_2', 0.014115857656463417), ('CONF_ID_team_1', 0.013032442198993188), ('G_team_2', 0.01075958941492209), ('Round', 0.009793199322534196), ('G_team_1', 0.00942301738707107)]\n",
      "\n",
      "Training classifier 'GaussianProcessClassifier'...\n",
      "GaussianProcessClassifier scores: 0.6093385214007783\twith {'max_iter_predict': 10}\n",
      "\n",
      "Selecting 'SVC' as best model with score: 0.7198443579766537\n"
     ]
    }
   ],
   "source": [
    "# run ML models\n",
    "models = []\n",
    "\n",
    "tune_params = [{'strategy': ['uniform'], 'random_state': [SEED]}]\n",
    "result = get_classifier_best(DummyClassifier, X, y, tune=None, strategy='uniform')\n",
    "models.append(result)\n",
    "\n",
    "tune_params = [{'fit_intercept': [True, False], 'positive': [True, False]}]\n",
    "result = get_classifier_best(LinearRegression, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = [{'learning_rate': [0.01,0.05,0.1,0.15], 'n_estimators': [50,100,200]}]\n",
    "result = get_classifier_best(GradientBoostingClassifier, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = {'C': [0.01, 0.1, 1.0, 2.0, 10.0, 20.0], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "result = get_classifier_best(SVC, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = {'loss': ['hinge','log','modified_huber','squared_hinge'], 'alpha': [0.0001, 0.001], \n",
    "    'learning_rate': ['optimal'], 'max_iter': [1E5]}\n",
    "result = get_classifier_best(SGDClassifier, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = {}\n",
    "result = get_classifier_best(GaussianNB, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = {}\n",
    "result = get_classifier_best(Perceptron, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = {'solver': ['lbfgs', 'adam'], 'batch_size': [16,32], 'hidden_layer_sizes': [(128), (128,64), (128,128,64), (512, 512, 128, 64)], 'max_iter': [10000]}\n",
    "result = get_classifier_best(MLPClassifier, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = {'n_estimators': [20,50,100,200], 'learning_rate': [0.01,0.1,0.5]}\n",
    "result = get_classifier_best(AdaBoostClassifier, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = {'n_neighbors': [3, 15, 25, 31], 'weights': ['uniform', 'distance'], 'p': [1, 2, 3]}\n",
    "result = get_classifier_best(KNeighborsClassifier, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = {'criterion': ['entropy', 'gini'], 'splitter': ['best', 'random']}\n",
    "result = get_classifier_best(DecisionTreeClassifier, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = {'n_estimators': [50, 100, 200], 'criterion': ['entropy', 'gini']}\n",
    "result = get_classifier_best(RandomForestClassifier, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "print()\n",
    "tune_params = {'max_iter_predict': [10, 100, 200]}\n",
    "result = get_classifier_best(GaussianProcessClassifier, X, y, tune=tune_params)\n",
    "models.append(result)\n",
    "\n",
    "best_model, best_score = max(models, key=lambda x: x[1])\n",
    "print('\\nSelecting \\'{}\\' as best model with score: {}'.format(best_model.__class__.__name__, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Bracket\n",
    "Now we can use the model to fill out this years tournament bracket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winner(team1, team2, round, model, dataset):\n",
    "    assert team1[1] in dataset['TEAM'].values, '{} not in data set'.format(team1[1])\n",
    "    assert team2[1] in dataset['TEAM'].values, '{} not in data set'.format(team2[1])\n",
    "\n",
    "    columns = ['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D', 'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD',\n",
    "                '2P_O', '2P_D', '3P_O', '3P_D', 'ADJ_T']\n",
    "    if ENCODE_CONF:\n",
    "        columns.append('CONF_ID')\n",
    "\n",
    "    # ['Round', 'Seed_1', 'Seed_2', *stat_features]\n",
    "    game_df = pd.DataFrame({'Round': [round], 'Seed_1': [team1[0]], 'Seed_2': [team2[0]]})\n",
    "    stats_team_1 = dataset[dataset['TEAM'] == team1[1]][columns].reset_index(drop=True)\n",
    "    stats_team_1 = stats_team_1.add_suffix('_team_1')\n",
    "    stats_team_2 = dataset[dataset['TEAM'] == team2[1]][columns].reset_index(drop=True)\n",
    "    stats_team_2 = stats_team_2.add_suffix('_team_2')\n",
    "    joined_df = pd.concat([game_df, stats_team_1, stats_team_2], axis=1)\n",
    "\n",
    "    if NORMALIZE:\n",
    "        joined_df[normalized_features] = scaler.transform(joined_df[normalized_features])\n",
    "    \n",
    "    pred = model.predict(joined_df)\n",
    "    return team1 if pred == 1 else team2\n",
    "\n",
    "\n",
    "def get_winners(games, round, model, dataset):\n",
    "    return [get_winner(t1, t2, round, model, dataset) for (t1, t2) in games]\n",
    "\n",
    "def simulate_tournament(bracket, model, dataset):\n",
    "\n",
    "    results = {\n",
    "        'west': [bracket['west']], 'east': [bracket['east']], \n",
    "        'south': [bracket['south']], 'midwest': [bracket['midwest']]\n",
    "        }\n",
    "\n",
    "    # go to final four (i.e. simulate each region until one team is left)\n",
    "    for region, brkt in bracket.items():\n",
    "        current_games = brkt\n",
    "        for round in range(1, 5):\n",
    "            current_games = get_winners(current_games, round, model, dataset)\n",
    "            if len(current_games) > 1:\n",
    "                current_games = [x for x in zip(current_games[::2], current_games[1::2])]\n",
    "            results[region].append(current_games)\n",
    "\n",
    "    # now do final-four, championship, and winner\n",
    "    results['final-four'] = [(results['west'][-1][0], results['east'][-1][0]), (results['south'][-1][0], results['midwest'][-1][0])]\n",
    "    \n",
    "    championship = get_winners(results['final-four'], 5, model, dataset)\n",
    "    results['championship'] = (championship[0], championship[1])\n",
    "    results['champion'] = get_winners([results['championship']], 6, model, dataset)[0]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_bracket(brkt, fp):\n",
    "\n",
    "    for region in ['west', 'east', 'south', 'midwest']:\n",
    "        print(region.upper(), file=fp)\n",
    "\n",
    "        line_ending = ' ---'\n",
    "        format_team = '({rank}) {team}'\n",
    "\n",
    "        rounds = brkt[region]\n",
    "\n",
    "        # compute widths\n",
    "        max_widths = []\n",
    "        for round in rounds[:-1]:\n",
    "            widths = []\n",
    "            for game in round:\n",
    "                team1, team2 = game\n",
    "                widths.append(len( format_team.format(rank=team1[0], team=team1[1]) ))\n",
    "                widths.append(len( format_team.format(rank=team2[0], team=team2[1]) ))\n",
    "\n",
    "            max_widths.append(max(widths))\n",
    "\n",
    "        def print_line(lineno):\n",
    "            round = int(math.log(lineno - (lineno & lineno - 1), 2))\n",
    "            indent = ' ' * (sum(max_widths[0:round]) + round*len(line_ending))\n",
    "\n",
    "            if round >= len(rounds):\n",
    "                return\n",
    "            \n",
    "            idx = (lineno//2**round)//2\n",
    "            games = rounds[round]\n",
    "            game = games[idx // 2]\n",
    "            if round == len(rounds)-1:\n",
    "                team = games[0]\n",
    "            else:\n",
    "                team = game[idx % 2]\n",
    "\n",
    "            print(indent + format_team.format(rank=team[0], team=team[1]) + line_ending, file=fp)\n",
    "\n",
    "        for lineno in range(len(rounds[0])*4):\n",
    "            print_line(lineno+1)\n",
    "\n",
    "        print('\\n', file=fp)\n",
    "\n",
    "    print('Final Four + Championship', file=fp)\n",
    "    final_four = brkt['final-four']\n",
    "    championship = brkt['championship']\n",
    "    champion = brkt['champion']\n",
    "    indent1 = ' '*25\n",
    "    indent2 = ' '*55\n",
    "    print(format_team.format(rank=final_four[0][0][0], team=final_four[0][0][1]).ljust(20) + line_ending, file=fp)\n",
    "    print(indent1 + format_team.format(rank=championship[0][0], team=championship[0][1]).ljust(20) + line_ending, file=fp)\n",
    "    print(format_team.format(rank=final_four[0][1][0], team=final_four[0][1][1]).ljust(20) + line_ending, file=fp)\n",
    "    print(indent2 + format_team.format(rank=champion[0], team=champion[1]).ljust(20), file=fp)\n",
    "    print(format_team.format(rank=final_four[1][0][0], team=final_four[1][0][1]).ljust(20) + line_ending, file=fp)\n",
    "    print(indent1 + format_team.format(rank=championship[1][0], team=championship[1][1]).ljust(20) + line_ending, file=fp)\n",
    "    print(format_team.format(rank=final_four[1][1][0], team=final_four[1][1][1]).ljust(20) + line_ending, file=fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022 brackets\n",
    "WEST = [((1, 'Gonzaga'), (16, 'Georgia St.')),\n",
    "\t((8, 'Boise St.'), (9, 'Memphis')),\n",
    "\t((5, 'Connecticut'), (12, 'New Mexico St.')),\n",
    "\t((4, 'Arkansas'), (13, 'Vermont')),\n",
    "\t((6, 'Alabama'), (11, 'Notre Dame')),\n",
    "\t((3, 'Texas Tech'), (14, 'Montana St.')),\n",
    "\t((7, 'Michigan St.'), (10, 'Davidson')),\n",
    "\t((2, 'Duke'), (15, 'Cal St. Fullerton'))\n",
    "\t]\n",
    "\t\n",
    "SOUTH = [((1, 'Arizona'), (16, 'Wright St.')),\n",
    "\t((8, 'Seton Hall'), (9, 'TCU')),\n",
    "\t((5, 'Houston'), (12, 'UAB')),\n",
    "\t((4, 'Illinois'), (13, 'Chattanooga')),\n",
    "\t((6, 'Colorado St.'), (11, 'Michigan')),\n",
    "\t((3, 'Tennessee'), (14, 'Longwood')),\n",
    "\t((7, 'Ohio St.'), (10, 'Loyola Chicago')),\n",
    "\t((2, 'Villanova'), (15, 'Delaware'))\n",
    "\t]\n",
    "\t\n",
    "EAST = [((1, 'Baylor'), (16, 'Norfolk St.')),\n",
    "\t((8, 'North Carolina'), (9, 'Marquette')),\n",
    "\t((5, 'Saint Mary\\'s'), (12, 'Indiana')),\n",
    "\t((4, 'UCLA'), (13, 'Akron')),\n",
    "\t((6, 'Texas'), (11, 'Virginia Tech')),\n",
    "\t((3, 'Purdue'), (14, 'Yale')),\n",
    "\t((7, 'Murray St.'), (10, 'San Francisco')),\n",
    "\t((2, 'Kentucky'), (15, 'Saint Peter\\'s'))\n",
    "\t]\n",
    "\n",
    "MIDWEST = [((1, 'Kansas'), (16, 'Texas Southern')),\n",
    "\t((8, 'San Diego St.'), (9, 'Creighton')),\n",
    "\t((5, 'Iowa'), (12, 'Richmond')),\n",
    "\t((4, 'Providence'), (13, 'South Dakota St.')),\n",
    "\t((6, 'LSU'), (11, 'Iowa St.')),\n",
    "\t((3, 'Wisconsin'), (14, 'Colgate')),\n",
    "\t((7, 'USC'), (10, 'Miami FL')),\n",
    "\t((2, 'Auburn'), (15, 'Jacksonville St.'))\n",
    "\t]\n",
    "\n",
    "R64 = {'west': WEST, 'south': SOUTH, 'east': EAST, 'midwest': MIDWEST}\n",
    "\n",
    "team_stats_df = pd.read_csv(path_join('data', 'raw_cbb.csv'), index_col=0)\n",
    "if ENCODE_CONF:\n",
    "\tteam_stats_df['CONF_ID'] = team_stats_df.groupby('CONF').ngroup().add(1)\n",
    "\n",
    "makedirs('results', exist_ok=True)\n",
    "for model, score in models:\n",
    "\tfpath = path_join('results', '{}_tournament.txt'.format(model.__class__.__name__))\n",
    "\twith open(fpath, 'w') as fp:\n",
    "\t\tfp.write('model: {}\\n'.format(model.__class__.__name__))\n",
    "\t\tfp.write('score: {}\\n'.format(score))\n",
    "\t\tfp.write('bracket: \\n')\n",
    "\t\t\n",
    "\t\tbrkt = simulate_tournament(R64, model, team_stats_df[team_stats_df['YEAR'] == 2022])\n",
    "\n",
    "\t\tprint_bracket(brkt, fp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
